{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaffa835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# Check the data\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d41086",
   "metadata": {},
   "outputs": [],
   "source": [
    "station=\"28079004\"\n",
    "df = pd.read_csv(f\"/home/sebas/data/air_qual_aemet/{station}.csv\",sep=\";\")\n",
    "# Limiting Date\n",
    "df = df[df[\"DATE\"]<\"2020-01-01\"]\n",
    "\n",
    "tdf = df[[\"DATE\",\"SPA.NO2\"]].copy()\n",
    "tdf.columns = [\"DATE\",\"NO2\"]\n",
    "tdf[\"NO2\"]=np.log1p(tdf[\"NO2\"])\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "stl = seasonal_decompose(tdf[\"NO2\"], model=\"additive\",period=24)\n",
    "tdf[\"NO2\"]=tdf[\"NO2\"]-stl.seasonal\n",
    "tdf[\"trend\"]=stl.trend\n",
    "\n",
    "horizon=13\n",
    "\n",
    "tdf[\"trend_norm\"]=tdf[\"trend\"].shift(horizon)\n",
    "\n",
    "# We remove the trend and keep past values\n",
    "for h in reversed(np.arange(0,3*24)):\n",
    "    if h>horizon:\n",
    "        tdf[f\"NO2 - {h}\"]=(tdf[\"NO2\"].shift(h)-tdf[\"trend_norm\"]).copy()\n",
    "\n",
    "tdf=tdf.dropna()\n",
    "\n",
    "cols = tdf.columns[tdf.columns.str.contains(\"NO2 -\")]\n",
    "X = tdf[cols].copy()\n",
    "y = tdf[[\"NO2\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4a556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NO2 - 71</th>\n",
       "      <th>NO2 - 70</th>\n",
       "      <th>NO2 - 69</th>\n",
       "      <th>NO2 - 68</th>\n",
       "      <th>NO2 - 67</th>\n",
       "      <th>NO2 - 66</th>\n",
       "      <th>NO2 - 65</th>\n",
       "      <th>NO2 - 64</th>\n",
       "      <th>NO2 - 63</th>\n",
       "      <th>NO2 - 62</th>\n",
       "      <th>...</th>\n",
       "      <th>NO2 - 23</th>\n",
       "      <th>NO2 - 22</th>\n",
       "      <th>NO2 - 21</th>\n",
       "      <th>NO2 - 20</th>\n",
       "      <th>NO2 - 19</th>\n",
       "      <th>NO2 - 18</th>\n",
       "      <th>NO2 - 17</th>\n",
       "      <th>NO2 - 16</th>\n",
       "      <th>NO2 - 15</th>\n",
       "      <th>NO2 - 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.313712</td>\n",
       "      <td>0.391156</td>\n",
       "      <td>0.230022</td>\n",
       "      <td>0.264430</td>\n",
       "      <td>0.033721</td>\n",
       "      <td>0.399788</td>\n",
       "      <td>0.200565</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.669540</td>\n",
       "      <td>0.330411</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136071</td>\n",
       "      <td>0.661447</td>\n",
       "      <td>0.718869</td>\n",
       "      <td>0.454474</td>\n",
       "      <td>0.428375</td>\n",
       "      <td>0.618041</td>\n",
       "      <td>0.814931</td>\n",
       "      <td>0.848639</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>-0.059054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.447698</td>\n",
       "      <td>0.286564</td>\n",
       "      <td>0.320972</td>\n",
       "      <td>0.090263</td>\n",
       "      <td>0.456330</td>\n",
       "      <td>0.257107</td>\n",
       "      <td>0.362316</td>\n",
       "      <td>0.726082</td>\n",
       "      <td>0.386953</td>\n",
       "      <td>-0.040637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717989</td>\n",
       "      <td>0.775411</td>\n",
       "      <td>0.511016</td>\n",
       "      <td>0.484917</td>\n",
       "      <td>0.674583</td>\n",
       "      <td>0.871473</td>\n",
       "      <td>0.905181</td>\n",
       "      <td>0.842342</td>\n",
       "      <td>-0.002512</td>\n",
       "      <td>-0.342918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.350767</td>\n",
       "      <td>0.385175</td>\n",
       "      <td>0.154465</td>\n",
       "      <td>0.520533</td>\n",
       "      <td>0.321310</td>\n",
       "      <td>0.426519</td>\n",
       "      <td>0.790285</td>\n",
       "      <td>0.451156</td>\n",
       "      <td>0.023566</td>\n",
       "      <td>0.247453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839614</td>\n",
       "      <td>0.575219</td>\n",
       "      <td>0.549120</td>\n",
       "      <td>0.738786</td>\n",
       "      <td>0.935676</td>\n",
       "      <td>0.969384</td>\n",
       "      <td>0.906545</td>\n",
       "      <td>0.061691</td>\n",
       "      <td>-0.278715</td>\n",
       "      <td>-0.531217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.445592</td>\n",
       "      <td>0.214882</td>\n",
       "      <td>0.580949</td>\n",
       "      <td>0.381726</td>\n",
       "      <td>0.486935</td>\n",
       "      <td>0.850701</td>\n",
       "      <td>0.511572</td>\n",
       "      <td>0.083983</td>\n",
       "      <td>0.307869</td>\n",
       "      <td>-0.280719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635635</td>\n",
       "      <td>0.609536</td>\n",
       "      <td>0.799203</td>\n",
       "      <td>0.996093</td>\n",
       "      <td>1.029800</td>\n",
       "      <td>0.966961</td>\n",
       "      <td>0.122108</td>\n",
       "      <td>-0.218298</td>\n",
       "      <td>-0.470800</td>\n",
       "      <td>-0.495830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.264408</td>\n",
       "      <td>0.630475</td>\n",
       "      <td>0.431252</td>\n",
       "      <td>0.536461</td>\n",
       "      <td>0.900227</td>\n",
       "      <td>0.561098</td>\n",
       "      <td>0.133508</td>\n",
       "      <td>0.357395</td>\n",
       "      <td>-0.231193</td>\n",
       "      <td>-0.413073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659062</td>\n",
       "      <td>0.848728</td>\n",
       "      <td>1.045618</td>\n",
       "      <td>1.079326</td>\n",
       "      <td>1.016487</td>\n",
       "      <td>0.171633</td>\n",
       "      <td>-0.168773</td>\n",
       "      <td>-0.421275</td>\n",
       "      <td>-0.446305</td>\n",
       "      <td>-0.368621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NO2 - 71  NO2 - 70  NO2 - 69  NO2 - 68  NO2 - 67  NO2 - 66  NO2 - 65  \\\n",
       "71  0.313712  0.391156  0.230022  0.264430  0.033721  0.399788  0.200565   \n",
       "72  0.447698  0.286564  0.320972  0.090263  0.456330  0.257107  0.362316   \n",
       "73  0.350767  0.385175  0.154465  0.520533  0.321310  0.426519  0.790285   \n",
       "74  0.445592  0.214882  0.580949  0.381726  0.486935  0.850701  0.511572   \n",
       "75  0.264408  0.630475  0.431252  0.536461  0.900227  0.561098  0.133508   \n",
       "\n",
       "    NO2 - 64  NO2 - 63  NO2 - 62  ...  NO2 - 23  NO2 - 22  NO2 - 21  NO2 - 20  \\\n",
       "71  0.305774  0.669540  0.330411  ...  1.136071  0.661447  0.718869  0.454474   \n",
       "72  0.726082  0.386953 -0.040637  ...  0.717989  0.775411  0.511016  0.484917   \n",
       "73  0.451156  0.023566  0.247453  ...  0.839614  0.575219  0.549120  0.738786   \n",
       "74  0.083983  0.307869 -0.280719  ...  0.635635  0.609536  0.799203  0.996093   \n",
       "75  0.357395 -0.231193 -0.413073  ...  0.659062  0.848728  1.045618  1.079326   \n",
       "\n",
       "    NO2 - 19  NO2 - 18  NO2 - 17  NO2 - 16  NO2 - 15  NO2 - 14  \n",
       "71  0.428375  0.618041  0.814931  0.848639  0.785800 -0.059054  \n",
       "72  0.674583  0.871473  0.905181  0.842342 -0.002512 -0.342918  \n",
       "73  0.935676  0.969384  0.906545  0.061691 -0.278715 -0.531217  \n",
       "74  1.029800  0.966961  0.122108 -0.218298 -0.470800 -0.495830  \n",
       "75  1.016487  0.171633 -0.168773 -0.421275 -0.446305 -0.368621  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6290c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1ab1463e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f966d5f2740>]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X.iloc[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "84c48fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56907, 58)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "2d7809c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = tdf[tdf[\"DATE\"]>\"2018\"].index.values[0]\n",
    "\n",
    "X_train=X[X.index<=TRAIN_SPLIT].copy()\n",
    "X_test=X[X.index>TRAIN_SPLIT].copy()\n",
    "y_train = y[X.index<=TRAIN_SPLIT].copy()\n",
    "y_test = y[X.index>TRAIN_SPLIT].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "5442b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train = torch.FloatTensor(X_train.values).to(device)\n",
    "X_test = torch.FloatTensor(X_test.values).to(device)\n",
    "y_train = torch.FloatTensor(y_train.values).to(device)\n",
    "y_test= torch.FloatTensor(y_test.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e4d3c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size = 56811\n",
    "# seq length = 154\n",
    "# N Features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "423efb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "98ea0ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm): LSTM(1, 64, batch_first=True)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    self.input_size = 1\n",
    "    self.output_size=1\n",
    "    self.hidden_dim=64\n",
    "    self.n_layers=1\n",
    "\n",
    "    super(Net,self).__init__() \n",
    "    self.lstm = nn.LSTM(self.input_size, self.hidden_dim, self.n_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(self.hidden_dim, self.output_size)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    h_0 = Variable(torch.zeros(self.n_layers, x.size(0), self.hidden_dim)).to(device)\n",
    "    c_0 = Variable(torch.zeros(self.n_layers, x.size(0), self.hidden_dim)).to(device)\n",
    "    \n",
    "    out, (hidden,_) = self.lstm(x,(h_0, c_0))\n",
    "    \n",
    "    h_out = hidden[-1].view(-1, self.hidden_dim)\n",
    "        \n",
    "    # get final output \n",
    "    output = self.fc(h_out)\n",
    "    \n",
    "    return output\n",
    "\n",
    "net = Net() \n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8b4d0d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39400, 58])"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "250c356f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39400, 58])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "# Must be:[batch_size, seq_len, input_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "c431bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#128 154 64\n",
    "\n",
    "#1  128 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e113d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X_train[:128,:].reshape([128, 58,1])).cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "825aaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "2bbb7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/harryliew/COCOB-optimizer/blob/master/cocob_bp.py\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "###########################################################################\n",
    "# Training Deep Networks without Learning Rates Through Coin Betting\n",
    "# Paper: https://arxiv.org/abs/1705.07795\n",
    "#\n",
    "# NOTE: This optimizer is hardcoded to run on GPU, needs to be parametrized\n",
    "###########################################################################\n",
    "\n",
    "class COCOBBackprop(optim.Optimizer):\n",
    "    \n",
    "    def __init__(self, params, alpha=100, epsilon=1e-8):\n",
    "        \n",
    "        self._alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        defaults = dict(alpha=alpha, epsilon=epsilon)\n",
    "        super(COCOBBackprop, self).__init__(params, defaults)\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        \n",
    "        loss = None\n",
    "        \n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "            \n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "        \n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "                \n",
    "                if len(state) == 0:\n",
    "                    state['gradients_sum'] = torch.zeros_like(p.data).cuda().float()\n",
    "                    state['grad_norm_sum'] = torch.zeros_like(p.data).cuda().float()\n",
    "                    state['L'] = self.epsilon * torch.ones_like(p.data).cuda().float()\n",
    "                    state['tilde_w'] = torch.zeros_like(p.data).cuda().float()\n",
    "                    state['reward'] = torch.zeros_like(p.data).cuda().float()\n",
    "                    \n",
    "                gradients_sum = state['gradients_sum']\n",
    "                grad_norm_sum = state['grad_norm_sum']\n",
    "                tilde_w = state['tilde_w']\n",
    "                L = state['L']\n",
    "                reward = state['reward']\n",
    "                \n",
    "                zero = torch.cuda.FloatTensor([0.])\n",
    "                \n",
    "                L_update = torch.max(L, torch.abs(grad))\n",
    "                gradients_sum_update = gradients_sum + grad\n",
    "                grad_norm_sum_update = grad_norm_sum + torch.abs(grad)\n",
    "                reward_update = torch.max(reward - grad * tilde_w, zero)\n",
    "                new_w = -gradients_sum_update/(L_update * (torch.max(grad_norm_sum_update + L_update, self._alpha * L_update)))*(reward_update + L_update)\n",
    "                p.data = p.data - tilde_w + new_w\n",
    "                tilde_w_update = new_w\n",
    "                \n",
    "                state['gradients_sum'] = gradients_sum_update\n",
    "                state['grad_norm_sum'] = grad_norm_sum_update\n",
    "                state['L'] = L_update\n",
    "                state['tilde_w'] = tilde_w_update\n",
    "                state['reward'] = reward_update\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "b16c41a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 11.220789909362793 Val Loss: 0.6711815426336336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 8.438915252685547 Val Loss: 0.6758005737435986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 8.319202423095703 Val Loss: 0.6912014042088487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 8.247286796569824 Val Loss: 0.7062880736040309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 8.219721794128418 Val Loss: 0.6883466963315177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/torch/nn/modules/rnn.py:761: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ../aten/src/ATen/native/cudnn/RNN.cpp:926.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 8.186166763305664 Val Loss: 0.6845761585193227\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = COCOBBackprop(net.parameters())\n",
    "batch_size = 32\n",
    "epochs = 6\n",
    "\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for j in range(epochs):\n",
    "    m_loss = []\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        train_features, train_labels = batch\n",
    "        y_hat = net.forward(train_features.reshape([len(train_features), 58,1])).to(device)\n",
    "        loss = criterion(y_hat, train_labels)\n",
    "        m_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test = TensorDataset(X_test, y_test)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "    predictions=np.array([])\n",
    "    for i,batch in enumerate(test_loader):\n",
    "        test_b = batch[0]\n",
    "        predictions = np.concatenate([predictions,net(test_b.reshape([len(test_b), 58,1])).cpu().reshape(-1).detach().numpy()])\n",
    "    #loss_arr.append(np.mean(m_loss))\n",
    "    #val_loss_arr.append(np.sqrt(mean_squared_error(predictions,y_test.cpu())))\n",
    "    print(f'Epoch: {j} Loss: {np.mean(m_loss)} Val Loss: {np.sqrt(mean_squared_error(predictions,y_test.cpu()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2dcd5243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 196.97494506835938 Val Loss: 0.5591471195220947\n",
      "Epoch: 1 Loss: 67.267822265625 Val Loss: 0.546899676322937\n",
      "Epoch: 2 Loss: 63.90300369262695 Val Loss: 0.5468499660491943\n",
      "Epoch: 3 Loss: 61.83918380737305 Val Loss: 0.5359558463096619\n",
      "Epoch: 4 Loss: 60.33985137939453 Val Loss: 0.5396912097930908\n",
      "Epoch: 5 Loss: 59.242061614990234 Val Loss: 0.5333669781684875\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "fulls = len(X_train.cpu()[0])\n",
    "mids = int(len(X_train.cpu()[0])/2)\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__() \n",
    "    self.whole = nn.Sequential(\n",
    "        nn.Linear(fulls,2*fulls),\n",
    "        nn.ReLU(),\n",
    "        nn.LayerNorm(2*fulls),\n",
    "        nn.Linear(2*fulls,mids),\n",
    "        nn.ReLU(),\n",
    "        nn.LayerNorm(mids),\n",
    "        nn.Linear(mids,1)\n",
    "        )\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.whole(x)\n",
    "    return x\n",
    "\n",
    "net = Net() \n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001,weight_decay=0.00001)\n",
    "#optimizer = COCOBBackprop(net.parameters())\n",
    "\n",
    "loss_arr = []\n",
    "val_loss_arr = []\n",
    "epochs = 6\n",
    "\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=256, shuffle=True)\n",
    "\n",
    "for j in range(epochs):\n",
    "  m_loss = []\n",
    "  for i,batch in enumerate(train_loader):\n",
    "    train_features, train_labels = batch\n",
    "    y_hat = net.forward(train_features).to(device)\n",
    "    loss = criterion(y_hat, train_labels)\n",
    "    m_loss.append(loss.detach().cpu().numpy())\n",
    " \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  predictions = net(X_test).cpu().reshape(-1).detach().numpy()\n",
    "  loss_arr.append(np.mean(m_loss))\n",
    "  val_loss_arr.append(np.sqrt(mean_squared_error(predictions,y_test.cpu())))\n",
    "  print(f'Epoch: {j} Loss: {np.mean(m_loss)} Val Loss: {np.sqrt(mean_squared_error(predictions,y_test.cpu()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "0fb43fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebas/miniconda3/envs/phd/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.524876815724352"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgbmodel = lgb.LGBMRegressor(n_estimators=1600,\n",
    "                                    random_state=2020,\n",
    "                                  max_depth=6)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lgbmodel.fit(X_train.cpu(),y_train.cpu())\n",
    "predictions = lgbmodel.predict(X_test.cpu())\n",
    "np.sqrt(mean_squared_error(predictions,y_test.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "86efad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 42.74711990356445 Val Loss: 0.5314860939979553\n",
      "Epoch: 1 Loss: 31.456073760986328 Val Loss: 0.5324621796607971\n",
      "Epoch: 2 Loss: 30.68372344970703 Val Loss: 0.5161141753196716\n",
      "Epoch: 3 Loss: 30.126129150390625 Val Loss: 0.529841423034668\n",
      "Epoch: 4 Loss: 29.706462860107422 Val Loss: 0.5315541625022888\n",
      "Epoch: 5 Loss: 29.397403717041016 Val Loss: 0.5171089172363281\n",
      "Epoch: 6 Loss: 29.298276901245117 Val Loss: 0.5103262662887573\n",
      "Epoch: 7 Loss: 29.208293914794922 Val Loss: 0.5163974761962891\n",
      "Epoch: 8 Loss: 28.884695053100586 Val Loss: 0.5162995457649231\n",
      "Epoch: 9 Loss: 28.63861846923828 Val Loss: 0.5253218412399292\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "n_channels = 64\n",
    "k_size = 3\n",
    "n_dil = 2\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__() \n",
    "    self.features = nn.Sequential(\n",
    "        nn.Conv1d(in_channels=1, out_channels=n_channels, kernel_size=k_size, padding=1),\n",
    "        nn.MaxPool1d(2),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    \n",
    "    self.regressor = nn.Sequential(\n",
    "        nn.LayerNorm(n_channels*29),\n",
    "        nn.Linear(n_channels*29,200),\n",
    "        nn.ReLU(),\n",
    "        nn.LayerNorm(200),\n",
    "        nn.Linear(200,1)\n",
    "    )\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = self.features(x)\n",
    "    #print(x.shape)\n",
    "    x = x.view(-1,n_channels*x.shape[2])\n",
    "    return self.regressor(x)\n",
    "\n",
    "net = Net() \n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = COCOBBackprop(net.parameters())\n",
    "\n",
    "loss_arr = []\n",
    "val_loss_arr = []\n",
    "epochs = 10\n",
    "\n",
    "X_train_gf = X_train.reshape(len(X_train),1,len(X_train[0]))\n",
    "train = TensorDataset(X_train_gf, y_train)\n",
    "train_loader = DataLoader(train, batch_size=128, shuffle=True)\n",
    "\n",
    "for j in range(epochs):\n",
    "    m_loss = []\n",
    "    for i,batch in enumerate(train_loader):\n",
    "      train_features, train_labels = batch\n",
    "      y_hat = net.forward(train_features)\n",
    "      loss = criterion(y_hat, train_labels)\n",
    "      m_loss.append(loss.cpu().detach().numpy())\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "    loss_arr.append(np.mean(m_loss))\n",
    "\n",
    "    X_test_gf = X_test.reshape(len(X_test),1,len(X_test[0]))\n",
    "    predictions = net(X_test_gf).cpu().reshape(-1).detach().numpy()\n",
    "    val_loss_arr.append(np.sqrt(mean_squared_error(predictions,y_test.cpu())))\n",
    "\n",
    "    print(f'Epoch: {j} Loss: {np.mean(m_loss)} Val Loss: {np.sqrt(mean_squared_error(predictions,y_test.cpu()))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28818690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
